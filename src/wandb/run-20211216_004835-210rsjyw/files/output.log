
Loaded base model.
/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
[INFO] [2021-12-16 00:48:43,750] Exp time: 2021-12-16_00h48m
[INFO] [2021-12-16 00:48:43,750] 	path: {'DB_ROOT': '../data/kaist-cvpr15', 'JSON_GT_FILE': 'kaist_annotations_test20.json'}
[INFO] [2021-12-16 00:48:43,750] 	train: {'wandb_enable': True, 'day': 'all', 'img_set': 'train-all-02.txt', 'checkpoint': None, 'batch_size': 40, 'start_epoch': 0, 'epochs': 40, 'epochs_since_improvement': 3, 'best_loss': 100.0, 'lr': 0.0001, 'momentum': 0.9, 'weight_decay': 0.0005, 'grad_clip': None, 'print_freq': 10, 'annotation': 'AR-CNN', 'img_transform': Compose(
    ColorJitter(brightness=[0.7, 1.3], contrast=[0.7, 1.3], saturation=[0.7, 1.3], hue=None)
    ColorJitterLWIR(brightness=None, contrast=[0.7, 1.3], saturation=None, hue=None)
), 'co_transform': Compose(
    TT_RandomHorizontalFlip(p=0.5)
    TT_RandomResizedCrop(size=[512, 640], scale=(0.25, 4.0), ratio=(0.8, 1.2), interpolation=PIL.Image.BILINEAR)
    ToTensor()
    Normalize(mean=[0.3465, 0.3219, 0.2842], std=[0.2358, 0.2265, 0.2274])
    Normalize(mean=[0.1598], std=[0.0813])
)}
[INFO] [2021-12-16 00:48:43,751] 	test: {'result_path': './result', 'day': 'all', 'img_set': 'test-all-20.txt', 'annotation': 'AR-CNN', 'input_size': [512.0, 640.0], 'checkpoint': './jobs/best_checkpoint.pth.tar', 'batch_size': 4, 'eval_batch_size': 1, 'img_transform': Compose(
), 'co_transform': Compose(
    Resize(size=[512.0, 640.0], interpolation=PIL.Image.BILINEAR)
    ToTensor()
    Normalize(mean=[0.3465, 0.3219, 0.2842], std=[0.2358, 0.2265, 0.2274])
    Normalize(mean=[0.1598], std=[0.0813])
)}
[INFO] [2021-12-16 00:48:43,751] 	dataset: {'workers': 8, 'OBJ_LOAD_CONDITIONS': {'train': {'hRng': [12, inf], 'xRng': [5, 635], 'yRng': [5, 507], 'wRng': [-inf, inf]}, 'test': {'hRng': [-inf, inf], 'xRng': [5, 635], 'yRng': [5, 507], 'wRng': [-inf, inf]}}}
[INFO] [2021-12-16 00:48:43,751] 	FDZ_case: {'original': ['None', 'None'], 'blackout_r': ['blackout', 'None'], 'blackout_t': ['None', 'blackout'], 'sidesblackout_a': ['SidesBlackout_R', 'SidesBlackout_L'], 'sidesblackout_b': ['SidesBlackout_L', 'SidesBlackout_R'], 'surroundingblackout': ['None', 'SurroundingBlackout']}
[INFO] [2021-12-16 00:48:43,751] 	device: cuda
[INFO] [2021-12-16 00:48:43,751] 	exp_name: None
[INFO] [2021-12-16 00:48:43,751] 	n_classes: 3
[INFO] [2021-12-16 00:48:43,751] 	upaired_augmentation: ['TT_RandomHorizontalFlip', 'TT_FixedHorizontalFlip', 'TT_RandomResizedCrop']
[INFO] [2021-12-16 00:48:43,751] 	jobs_dir: jobs/2021-12-16_00h48m_
[INFO] [2021-12-16 00:48:43,751] Preprocess for training
[INFO] [2021-12-16 00:48:43,751] Compose(
    ColorJitter(brightness=[0.7, 1.3], contrast=[0.7, 1.3], saturation=[0.7, 1.3], hue=None)
    ColorJitterLWIR(brightness=None, contrast=[0.7, 1.3], saturation=None, hue=None)
)
[INFO] [2021-12-16 00:48:43,751] Transforms for training
[INFO] [2021-12-16 00:48:43,751] Compose(
    TT_RandomHorizontalFlip(p=0.5)
    TT_RandomResizedCrop(size=[512, 640], scale=(0.25, 4.0), ratio=(0.8, 1.2), interpolation=PIL.Image.BILINEAR)
    ToTensor()
    Normalize(mean=[0.3465, 0.3219, 0.2842], std=[0.2358, 0.2265, 0.2274])
    Normalize(mean=[0.1598], std=[0.0813])
)
[INFO] [2021-12-16 00:48:43,751] #################### << Epoch   0 >> ####################
Traceback (most recent call last):
  File "train_eval.py", line 235, in <module>
    main()
  File "train_eval.py", line 115, in main
    **kwargs)
  File "train_eval.py", line 186, in train_epoch
    predicted_locs, predicted_scores = model(image_vis, image_lwir)  # (N, 8732, 4), (N, 8732, n_classes)
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 1 on device 1.
Original Traceback (most recent call last):
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hjkim/workspace/MLPD-Multi-Label-Pedestrian-Detection/src/model.py", line 713, in forward
    conv4_3_feats, conv6_feats , conv7_feats, conv8_feats, conv9_feats, conv10_feats = self.base(image_vis, image_lwir)
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hjkim/workspace/MLPD-Multi-Label-Pedestrian-Detection/src/model.py", line 385, in forward
    out_lwir = F.relu(self.conv1_1_bn_lwir(self.conv1_1_lwir(image_lwir)))
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/functional.py", line 1299, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 1.56 GiB (GPU 1; 39.59 GiB total capacity; 18.98 GiB already allocated; 195.19 MiB free; 20.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF