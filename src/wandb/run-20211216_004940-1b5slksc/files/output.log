
Loaded base model.
/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
[INFO] [2021-12-16 00:49:47,810] Exp time: 2021-12-16_00h49m
[INFO] [2021-12-16 00:49:47,810] 	path: {'DB_ROOT': '../data/kaist-cvpr15', 'JSON_GT_FILE': 'kaist_annotations_test20.json'}
[INFO] [2021-12-16 00:49:47,810] 	train: {'wandb_enable': True, 'day': 'all', 'img_set': 'train-all-02.txt', 'checkpoint': None, 'batch_size': 40, 'start_epoch': 0, 'epochs': 40, 'epochs_since_improvement': 3, 'best_loss': 100.0, 'lr': 0.0001, 'momentum': 0.9, 'weight_decay': 0.0005, 'grad_clip': None, 'print_freq': 10, 'annotation': 'AR-CNN', 'img_transform': Compose(
    ColorJitter(brightness=[0.7, 1.3], contrast=[0.7, 1.3], saturation=[0.7, 1.3], hue=None)
    ColorJitterLWIR(brightness=None, contrast=[0.7, 1.3], saturation=None, hue=None)
), 'co_transform': Compose(
    TT_RandomHorizontalFlip(p=0.5)
    TT_RandomResizedCrop(size=[512, 640], scale=(0.25, 4.0), ratio=(0.8, 1.2), interpolation=PIL.Image.BILINEAR)
    ToTensor()
    Normalize(mean=[0.3465, 0.3219, 0.2842], std=[0.2358, 0.2265, 0.2274])
    Normalize(mean=[0.1598], std=[0.0813])
)}
[INFO] [2021-12-16 00:49:47,810] 	test: {'result_path': './result', 'day': 'all', 'img_set': 'test-all-20.txt', 'annotation': 'AR-CNN', 'input_size': [512.0, 640.0], 'checkpoint': './jobs/best_checkpoint.pth.tar', 'batch_size': 4, 'eval_batch_size': 1, 'img_transform': Compose(
), 'co_transform': Compose(
    Resize(size=[512.0, 640.0], interpolation=PIL.Image.BILINEAR)
    ToTensor()
    Normalize(mean=[0.3465, 0.3219, 0.2842], std=[0.2358, 0.2265, 0.2274])
    Normalize(mean=[0.1598], std=[0.0813])
)}
[INFO] [2021-12-16 00:49:47,810] 	dataset: {'workers': 8, 'OBJ_LOAD_CONDITIONS': {'train': {'hRng': [12, inf], 'xRng': [5, 635], 'yRng': [5, 507], 'wRng': [-inf, inf]}, 'test': {'hRng': [-inf, inf], 'xRng': [5, 635], 'yRng': [5, 507], 'wRng': [-inf, inf]}}}
[INFO] [2021-12-16 00:49:47,810] 	FDZ_case: {'original': ['None', 'None'], 'blackout_r': ['blackout', 'None'], 'blackout_t': ['None', 'blackout'], 'sidesblackout_a': ['SidesBlackout_R', 'SidesBlackout_L'], 'sidesblackout_b': ['SidesBlackout_L', 'SidesBlackout_R'], 'surroundingblackout': ['None', 'SurroundingBlackout']}
[INFO] [2021-12-16 00:49:47,810] 	device: cuda
[INFO] [2021-12-16 00:49:47,810] 	exp_name: None
[INFO] [2021-12-16 00:49:47,810] 	n_classes: 3
[INFO] [2021-12-16 00:49:47,810] 	upaired_augmentation: ['TT_RandomHorizontalFlip', 'TT_FixedHorizontalFlip', 'TT_RandomResizedCrop']
[INFO] [2021-12-16 00:49:47,810] 	jobs_dir: jobs/2021-12-16_00h49m_
[INFO] [2021-12-16 00:49:47,810] Preprocess for training
[INFO] [2021-12-16 00:49:47,810] Compose(
    ColorJitter(brightness=[0.7, 1.3], contrast=[0.7, 1.3], saturation=[0.7, 1.3], hue=None)
    ColorJitterLWIR(brightness=None, contrast=[0.7, 1.3], saturation=None, hue=None)
)
[INFO] [2021-12-16 00:49:47,810] Transforms for training
[INFO] [2021-12-16 00:49:47,811] Compose(
    TT_RandomHorizontalFlip(p=0.5)
    TT_RandomResizedCrop(size=[512, 640], scale=(0.25, 4.0), ratio=(0.8, 1.2), interpolation=PIL.Image.BILINEAR)
    ToTensor()
    Normalize(mean=[0.3465, 0.3219, 0.2842], std=[0.2358, 0.2265, 0.2274])
    Normalize(mean=[0.1598], std=[0.0813])
)
[INFO] [2021-12-16 00:49:47,811] #################### << Epoch   0 >> ####################
[INFO] [2021-12-16 00:50:04,679] Iteration: [0/628]	Batch Time 16.867 (16.867)	Data Time 4.396 (4.396)	Loss 30.3154 (30.3154)	num of Positive tensor([137,   6,   0, 148,   2,   8,   0,   0,  50,   0,  45, 102,   0,   0,
          0,   0,   0,   0,  71,   0,   3,   0,   0,   0,   0, 102,   0, 119,
          0, 183,   0,   0,  78,  13,   0,   0,  45,   3,  61,  34],
       device='cuda:0')	
Traceback (most recent call last):
  File "train_eval.py", line 235, in <module>
    main()
  File "train_eval.py", line 115, in main
    **kwargs)
  File "train_eval.py", line 198, in train_epoch
    loss.backward()
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/envs/hjkim/lib/python3.7/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 39.59 GiB total capacity; 36.95 GiB already allocated; 92.19 MiB free; 37.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF